Sun 10 Dec 2023 02:00:24 INFO  ['main.py', '--config-file', 'context_aware/NFM.yaml']
Sun 10 Dec 2023 02:00:24 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = ./dataset/discovery
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 500
train_batch_size = 1024
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'groupby': 'user'}
repeatable = False
metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']
topk = [10]
valid_metric = MRR@10
valid_metric_bigger = True
eval_batch_size = 2048
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'item': ['item_id', 'type']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [10, inf)
item_inter_num_interval = [20, inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 64
mlp_hidden_size = [64, 64, 64]
dropout_prob = 0.0
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.CONTEXT
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


Sun 10 Dec 2023 02:00:27 INFO  discovery
The number of users: 11281
Average actions of users: 23.533510638297873
The number of items: 5739
Average actions of items: 46.26315789473684
The number of inters: 265458
The sparsity of the dataset: 99.58997343580583%
Remain Fields: ['user_id', 'item_id', 'timestamp', 'type']
Sun 10 Dec 2023 02:00:28 INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]
Sun 10 Dec 2023 02:00:28 INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'groupby': 'user'}]
Sun 10 Dec 2023 02:00:29 INFO  NFM(
  (token_embedding_table): FMEmbedding(
    (embedding): Embedding(17024, 64)
  )
  (first_order_linear): FMFirstOrderLinear(
    (token_embedding_table): FMEmbedding(
      (embedding): Embedding(17024, 1)
    )
  )
  (fm): BaseFactorizationMachine()
  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.0, inplace=False)
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Sigmoid()
      (4): Dropout(p=0.0, inplace=False)
      (5): Linear(in_features=64, out_features=64, bias=True)
      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): Sigmoid()
      (8): Dropout(p=0.0, inplace=False)
      (9): Linear(in_features=64, out_features=64, bias=True)
      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): Sigmoid()
    )
  )
  (predict_layer): Linear(in_features=64, out_features=1, bias=False)
  (sigmoid): Sigmoid()
  (loss): BCEWithLogitsLoss()
)
Trainable parameters: 1119617
Sun 10 Dec 2023 02:00:29 INFO  FLOPs: 13571.0
Sun 10 Dec 2023 02:00:30 INFO  Time: 0.1766529083251953
Sun 10 Dec 2023 02:00:32 INFO  epoch 0 training [time: 2.17s, train loss: 291.5643]
Sun 10 Dec 2023 02:01:28 INFO  epoch 0 evaluating [time: 56.43s, valid_score: 0.008700]
Sun 10 Dec 2023 02:01:28 INFO  valid result: 
recall@10 : 0.0116    mrr@10 : 0.0087    ndcg@10 : 0.0072    hit@10 : 0.0242    precision@10 : 0.0024
Sun 10 Dec 2023 02:01:28 INFO  Saving current: saved/NFM-Dec-10-2023_02-00-29.pth
Sun 10 Dec 2023 02:01:31 INFO  epoch 1 training [time: 2.38s, train loss: 272.0960]
Sun 10 Dec 2023 02:02:30 INFO  epoch 1 evaluating [time: 58.95s, valid_score: 0.008700]
Sun 10 Dec 2023 02:02:30 INFO  valid result: 
recall@10 : 0.0133    mrr@10 : 0.0087    ndcg@10 : 0.0077    hit@10 : 0.0259    precision@10 : 0.0026
Sun 10 Dec 2023 02:02:30 INFO  Saving current: saved/NFM-Dec-10-2023_02-00-29.pth
Sun 10 Dec 2023 02:02:32 INFO  epoch 2 training [time: 2.37s, train loss: 236.0037]
Sun 10 Dec 2023 02:03:30 INFO  epoch 2 evaluating [time: 57.71s, valid_score: 0.008000]
Sun 10 Dec 2023 02:03:30 INFO  valid result: 
recall@10 : 0.0117    mrr@10 : 0.008    ndcg@10 : 0.0069    hit@10 : 0.0235    precision@10 : 0.0024
Sun 10 Dec 2023 02:03:32 INFO  epoch 3 training [time: 2.36s, train loss: 188.2384]
Sun 10 Dec 2023 02:04:31 INFO  epoch 3 evaluating [time: 58.76s, valid_score: 0.006400]
Sun 10 Dec 2023 02:04:31 INFO  valid result: 
recall@10 : 0.0111    mrr@10 : 0.0064    ndcg@10 : 0.006    hit@10 : 0.021    precision@10 : 0.0021
Sun 10 Dec 2023 02:04:33 INFO  epoch 4 training [time: 2.49s, train loss: 149.5148]
Sun 10 Dec 2023 02:05:30 INFO  epoch 4 evaluating [time: 57.17s, valid_score: 0.005000]
Sun 10 Dec 2023 02:05:30 INFO  valid result: 
recall@10 : 0.0092    mrr@10 : 0.005    ndcg@10 : 0.0049    hit@10 : 0.0176    precision@10 : 0.0018
Sun 10 Dec 2023 02:05:33 INFO  epoch 5 training [time: 2.45s, train loss: 125.8316]
Sun 10 Dec 2023 02:06:30 INFO  epoch 5 evaluating [time: 56.73s, valid_score: 0.004400]
Sun 10 Dec 2023 02:06:30 INFO  valid result: 
recall@10 : 0.008    mrr@10 : 0.0044    ndcg@10 : 0.0042    hit@10 : 0.0142    precision@10 : 0.0014
Sun 10 Dec 2023 02:06:32 INFO  epoch 6 training [time: 2.38s, train loss: 110.5552]
Sun 10 Dec 2023 02:07:31 INFO  epoch 6 evaluating [time: 58.85s, valid_score: 0.003500]
Sun 10 Dec 2023 02:07:31 INFO  valid result: 
recall@10 : 0.0073    mrr@10 : 0.0035    ndcg@10 : 0.0038    hit@10 : 0.0115    precision@10 : 0.0012
Sun 10 Dec 2023 02:07:33 INFO  epoch 7 training [time: 2.42s, train loss: 101.3834]
Sun 10 Dec 2023 02:08:30 INFO  epoch 7 evaluating [time: 56.85s, valid_score: 0.002600]
Sun 10 Dec 2023 02:08:30 INFO  valid result: 
recall@10 : 0.006    mrr@10 : 0.0026    ndcg@10 : 0.003    hit@10 : 0.0087    precision@10 : 0.0009
Sun 10 Dec 2023 02:08:33 INFO  epoch 8 training [time: 2.44s, train loss: 94.2850]
Sun 10 Dec 2023 02:09:29 INFO  epoch 8 evaluating [time: 56.74s, valid_score: 0.002300]
Sun 10 Dec 2023 02:09:29 INFO  valid result: 
recall@10 : 0.0054    mrr@10 : 0.0023    ndcg@10 : 0.0026    hit@10 : 0.0094    precision@10 : 0.0009
Sun 10 Dec 2023 02:09:32 INFO  epoch 9 training [time: 2.35s, train loss: 87.6994]
Sun 10 Dec 2023 02:10:29 INFO  epoch 9 evaluating [time: 57.16s, valid_score: 0.003600]
Sun 10 Dec 2023 02:10:29 INFO  valid result: 
recall@10 : 0.0072    mrr@10 : 0.0036    ndcg@10 : 0.0037    hit@10 : 0.0125    precision@10 : 0.0013
Sun 10 Dec 2023 02:10:31 INFO  epoch 10 training [time: 2.46s, train loss: 83.1916]
Sun 10 Dec 2023 02:11:28 INFO  epoch 10 evaluating [time: 56.86s, valid_score: 0.003500]
Sun 10 Dec 2023 02:11:28 INFO  valid result: 
recall@10 : 0.0069    mrr@10 : 0.0035    ndcg@10 : 0.0036    hit@10 : 0.0118    precision@10 : 0.0012
Sun 10 Dec 2023 02:11:31 INFO  epoch 11 training [time: 2.49s, train loss: 80.6549]
Sun 10 Dec 2023 02:12:30 INFO  epoch 11 evaluating [time: 59.21s, valid_score: 0.003200]
Sun 10 Dec 2023 02:12:30 INFO  valid result: 
recall@10 : 0.0071    mrr@10 : 0.0032    ndcg@10 : 0.0036    hit@10 : 0.0109    precision@10 : 0.0011
Sun 10 Dec 2023 02:12:32 INFO  epoch 12 training [time: 2.36s, train loss: 77.4048]
Sun 10 Dec 2023 02:13:31 INFO  epoch 12 evaluating [time: 59.10s, valid_score: 0.003600]
Sun 10 Dec 2023 02:13:31 INFO  valid result: 
recall@10 : 0.0073    mrr@10 : 0.0036    ndcg@10 : 0.0037    hit@10 : 0.0121    precision@10 : 0.0012
Sun 10 Dec 2023 02:13:31 INFO  Finished training, best eval result in epoch 1
Sun 10 Dec 2023 02:13:31 INFO  Loading model structure and parameters from saved/NFM-Dec-10-2023_02-00-29.pth
Sun 10 Dec 2023 02:14:28 INFO  The running environment of this training is as follows:
+-------------+---------------+
| Environment |     Usage     |
+=============+===============+
| CPU         |    1.00 %     |
+-------------+---------------+
| GPU         | 0.06 G/3.81 G |
+-------------+---------------+
| Memory      | 3.26 G/7.62 G |
+-------------+---------------+
Sun 10 Dec 2023 02:14:28 INFO  best valid : OrderedDict([('recall@10', 0.0133), ('mrr@10', 0.0087), ('ndcg@10', 0.0077), ('hit@10', 0.0259), ('precision@10', 0.0026)])
Sun 10 Dec 2023 02:14:28 INFO  test result: OrderedDict([('recall@10', 0.0124), ('mrr@10', 0.0089), ('ndcg@10', 0.0078), ('hit@10', 0.0249), ('precision@10', 0.0025)])
